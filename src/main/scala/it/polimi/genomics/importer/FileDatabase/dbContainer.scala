package it.polimi.genomics.importer.FileDatabase

import org.joda.time.DateTime
import org.slf4j.{Logger, LoggerFactory}
import slick.dbio.Effect.Write
import slick.driver.H2Driver.api._
import slick.driver.H2Driver.backend.DatabaseDef
import slick.jdbc.meta.MTable
import slick.profile.FixedSqlAction

import scala.concurrent.Await
import scala.concurrent.duration.Duration
/**
  * Created by nachon on 11/11/16.
  * dbContainder is the interface between the h2 database and the file logger.
  * for the development of GMQLImporter all the asynchronous operations in the database are done
  * synchronous waiting them to finish.
  *
  * How to use it properly:
  *   1- Instantiate the class and set it up by giving the database path in the setDatabase method.
  *      This has to be done at the beginning of the usage of the database, same instantiation should be used
  *      for all the sources and dataset contained in the same xml configuration file.
  *
  *   2- For getting the source/dataset/file IDs sourceId/datasetId/fileId are provided.
  *
  *   3- For providing feedback about which files are outdated, before starting checking if the files of a dataset
  *      have to be updated, mark the dataset to be compared with the markToCompare method.
  *
  *   4- For each file, the checkIfUpdate(...) method will indicate if that file has to be updated.
  *     4.1- After you update the file (if you have to) use markAsUpdated(...) method to indicate that was updated.
  *     4.2- If the update process was not correct, use markAsFailed(...) method to indicate that was an error.
  *
  *   5- After modifications have been done and comparisons for the dataset have finished, use method markAsOutdated()
  *      to identify and mark the outdated files.
  *
  *   6- You can get lists of files to be processed getFilesToProcess() method. Returns "UPDATE" status.
  *
  *   7- After you use the information in the log (as example, when the transformer uses info generated by downloader)
  *       log it by using the method markAsProcessed().
  */
case class dbContainer() {
  val logger: Logger = LoggerFactory.getLogger(this.getClass)
  //------------------------------------------------testing space-------------------------------------------------------
  def printWholeDatabase(): Unit = {
    Await.result(database.run((for (r<- runs) yield (
      r.id,r.datetimeStart,r.datetimeEnd,r.downloadEnabled,r.transformEnabled,r.loadEnabled,r.outputFolder))
      .result),Duration.Inf).foreach(run=>{
      println("Run: " + run._1 +"\t"+run._2 +"\t"+run._3 +"\t"+run._4 +"\t"+run._5 +"\t"+run._6 +"\t"+run._7)
    })
    Await.result(database.run((for (s <- sources) yield (s.id, s.name)).result), Duration.Inf).foreach(source => {
      println("Source: " + source._1 + "-" + source._2)
      println("\tRunSources:")
      Await.result(database.run((for (rs <- runSources.filter(_.sourceId === source._1)) yield (
        rs.id, rs.runId, rs.sourceId, rs.url, rs.outputFolder, rs.downloadEnabled, rs.downloader, rs.transformEnabled,
        rs.transformer, rs.loadEnabled, rs.loader)).result), Duration.Inf).foreach(runSource => {
        println("\t\tRunSource: " + runSource._1 + "\t" + runSource._2 + "\t" + runSource._3 + "\t" + runSource._4 +
          "\t" + runSource._5 + "\t" + runSource._6 + "\t" + runSource._7 + "\t" + runSource._8 + "\t" + runSource._9 +
          "\t" + runSource._10 + "\t" + runSource._11)
        println("\t\t\tRunSourceParameters:")
        Await.result(database.run((for (rsp <- runSourceParameters.filter(_.runSourceId === runSource._1)) yield (
          rsp.id, rsp.runSourceId, rsp.description, rsp.key, rsp.value)).result), Duration.Inf)
          .foreach(runSourceParameter => {
            println("\t\t\t\tRunSourceParameter: " + runSourceParameter._1 + "\t" + runSourceParameter._2 + "\t" +
              runSourceParameter._3 + "\t" + runSourceParameter._4 + "\t" + runSourceParameter._5)
        })
      })
      println("\tDatasets:")
      Await.result(database.run((for (d <- datasets.filter(_.sourceId === source._1)) yield (d.id, d.sourceId, d.name))
        .result), Duration.Inf).foreach(dataset => {
        println("\t\tDataset: " + dataset._1 + "\t" + dataset._2 + "\t" + dataset._3)
        println("\t\t\tRunDatasets:")
        Await.result(database.run((for (rd <- runDatasets.filter(_.datasetId === dataset._1)) yield (
          rd.id, rd.runId, rd.datasetId, rd.outputFolder, rd.downloadEnabled, rd.transformEnabled, rd.loadEnabled,
          rd.schemaLocation, rd.schemaUrl)).result), Duration.Inf).foreach(runDataset => {
          println("\t\t\t\tRunDataset: " + runDataset._1 + "\t" + runDataset._2 + "\t" + runDataset._3 + "\t" +
            runDataset._4 + "\t" + runDataset._5 + "\t" + runDataset._6 + "\t" + runDataset._7 + "\t" +
            runDataset._8 + "\t" + runDataset._9)
          println("\t\t\t\t\tRunDatasetPatameters:")
          Await.result(database.run((for (rdp <- runDatasetParameters.filter(_.runDatasetId === runDataset._1)) yield (
            rdp.id, rdp.runDatasetId, rdp.description, rdp.key, rdp.value)).result), Duration.Inf)
            .foreach(runDatasetParameter => {
            println("\t\t\t\t\t\tRunDatasetParameter: " + runDatasetParameter._1 + "\t" + runDatasetParameter._2 +
              "\t" + runDatasetParameter._3 + "\t" + runDatasetParameter._4 + "\t" + runDatasetParameter._5)
          })
        })
        println("\t\t\tFiles:")
        Await.result(database.run((for (f <- files.filter(_.datasetId === dataset._1)) yield (
          f.id, f.datasetId, f.url, f.name, f.stage, f.status, f.size, f.lastUpdate, f.hash, f.originSize,
          f.originLastUpdate, f.dateProcessed, f.copyNumber)).result), Duration.Inf).foreach(file => {
          println("\t\t\t\tFile: " + file._1 + "\t" + file._2 + "\t" + file._3 + "\t" + file._4 + "\t" + file._5 +
            "\t" + file._6 + "\t" + file._7 + "\t" + file._8 + "\t" + file._9 + "\t" + file._10 + "\t" + file._11 +
            "\t" + file._12 + "\t" + file._13)
          println("\t\t\t\t\tRunFiles:")
          Await.result(database.run((for (rf <- runFiles.filter(_.fileId === file._1)) yield (
            rf.id, rf.runId, rf.fileId, rf.status, rf.size, rf.lastUpdate, rf.hash, rf.originSize,
            rf.originLastUpdate, rf.dateProcessed)).result), Duration.Inf).foreach(runFile => {
            println("\t\t\t\t\t\tRunFile: " + runFile._1 + "\t" + runFile._2 + "\t" + runFile._3 + "\t" +
              runFile._4 + "\t" + runFile._5 + "\t" + runFile._6 + "\t" + runFile._7 + "\t" + runFile._8 + "\t" +
              runFile._9 + "\t" + runFile._10 + "\t")
          })
        })
      })
    })
  }
  //-------------------------------------DATABASE DEFINITION------------------------------------------------------------
  var database: DatabaseDef = _
  //------------------------------------------LOG PRINTING--------------------------------------------------------------
  /**
    * prints the log for dataset downloaded files for a specified run
    * @param runDatasetId identifies of the rundataset.
    */
  def printRunDatasetLog(runDatasetId: Int, stage: STAGE.Value): Unit ={
    val query = (for (f <- runDatasetLogs.filter(f => f.id === runDatasetId && f.stage === stage.toString))
      yield (f.totalFiles,f.downloadedFiles)).result
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)
    var totalFiles = 0
    var downloadedFiles = 0
    result.foreach(log => {
      totalFiles = totalFiles + log._1
      downloadedFiles = downloadedFiles + log._2
    })

    val datasetQuery = (for (f <- runDatasets.filter(f => f.id === runDatasetId)) yield (f.datasetId)).result
    val datasetExecution = database.run(datasetQuery)
    val datasetResult = Await.result(datasetExecution,Duration.Inf)
    val datasetId = datasetResult.head

    val datasetNameQuery = (for (f <- datasets.filter(f => f.id === datasetId)) yield (f.name)).result
    val datasetNameExecution = database.run(datasetNameQuery)
    val datasetNameResult = Await.result(datasetNameExecution,Duration.Inf)
    val datasetName = datasetNameResult.head

    logger.info(s"\tDataset $datasetName download statistics:")
    logger.info(s"\t\tTotal files to download: $totalFiles")
    logger.info(s"\t\tDownloaded files: $downloadedFiles")

  }
  //-------------------------------BASIC INSERTIONS SOURCE/DATASET/FILE/RUN---------------------------------------------
  /**
    * Tries to create a source with the given name and returns its id, if already exists is not replaced.
    * @param name name of the source, should be unique.
    * @return id of the source.
    */
  def sourceId(name: String): Int ={
    val query = (for (s <- sources.filter(_.name === name)) yield s.id).result
    val execution= database.run(query)
    val result = Await.result(execution,Duration.Inf)

    if(result.nonEmpty)
      result.head
      //here I have to create the source.
    else {
      val idQuery = (sources returning sources.map(_.id)) += (None, name)
      val executionId = database.run(idQuery)
      val resultId = Await.result(executionId,Duration.Inf)
      resultId
    }
  }

  /**
    * Tries to create a dataset and returns its id, if already exists is not replaced.
    * @param sourceId dataset owner's id
    * @param name name of the dataset should be unique for each source.
    * @return id of the dataset.
    */
  def datasetId(sourceId: Int, name: String): Int = {
    val query = (for (s <- datasets.filter(ds => ds.sourceId === sourceId && ds.name === name)) yield s.id).result
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)

    if (result.nonEmpty)
      result.head
    //here I have to create the dataset.
    else {
      val idQuery: FixedSqlAction[Int, NoStream, Write] = (datasets returning datasets.map(_.id)) +=
        (None, sourceId, name)
      val executionId = database.run(idQuery)
      val resultId = Await.result(executionId, Duration.Inf)
      resultId
    }
  }

  /**
    * Tries to create a file and returns its id, if already exists is not replaced.
    * @param datasetId file owner's id.
    * @param url origin url for the file.
    * @param stage stage of the process the file is used Download/Transform.
    * @param candidateName the name the file should have.
    * @return id of the file.
    */
  def fileId(datasetId: Int, url: String, stage: STAGE.Value, candidateName: String): Int = {
    val query = (for (s <- files.filter(f =>
      f.datasetId === datasetId && f.url === url && f.stage === stage.toString && f.name === candidateName))
      yield s.id).result
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)

    if (result.nonEmpty)
      result.head
    //here I have to create the file.
    else {
      val idQuery: FixedSqlAction[Int, NoStream, Write] = (files returning files.map(_.id)) +=
        (None, datasetId, url, candidateName, stage.toString, "FAILED", "", "", "", "", "", "",0)
      //FAILED STATUS IS GIVEN BY DEFAULT WHEN CREATING A FILE (MEANS HAVE NOT BEEN DOWNLOADED)
      val executionId = database.run(idQuery)
      val resultId = Await.result(executionId, Duration.Inf)
      resultId
    }
  }

  /**
    * Creates a run, with its general settings and the actual datetime.
    * @param downloadEnabled indicates if downloading was enabled during the run.
    * @param transformEnabled indicates if transforming was enabled during the run.
    * @param loadEnabled indicates if loading was enabled during the run.
    * @param outputFolder indicates the outputFolder defined as working directory.
    * @return the run's id.
    */
  def runId(downloadEnabled: String, transformEnabled: String, loadEnabled: String, outputFolder: String): Int = {
    val dateTimeStart = DateTime.now().toString
    //runs have always to be created.
    val query = (runs returning runs.map(_.id)) +=
      (None,dateTimeStart,"",downloadEnabled,transformEnabled,loadEnabled,outputFolder)
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)
    if(result > 1) {
      val pastRunId = result - 1
      val updateQuery = (for (f <- runs.filter(r => r.id === pastRunId && r.datetimeEnd === ""))
        yield f.datetimeEnd)
        .update(dateTimeStart)
      Await.result(database.run(updateQuery), Duration.Inf)
    }
    result
  }

  //--------------------------SECONDARY INSERTIONS RUNSOURCE/RUNDATASET/RUNFILE/PARAMETERS------------------------------

  /**
    * generates the last representation of the source in the last run.
    * @param sourceId id for the source.
    * @param url url for the source.
    * @param outputFolder working directory for the source.
    * @param downloadEnabled indicates if the source is being downloaded.
    * @param downloader indicates the downloader used for the source.
    * @param transformEnabled indicates if the source is being transformed.
    * @param transformer indicates the transformer used by the source.
    * @param loadEnabled indicates if the source is bein loaded.
    * @param loader indicates the loader used by the source.
    * @return the runSource id.
    */
  def runSourceId(sourceId: Int, url: String, outputFolder: String,
                  downloadEnabled: String, downloader: String, transformEnabled: String,
                  transformer: String, loadEnabled: String, loader: String
                 ): Int = {
    val runId = getMaxRunNumber
    val query = (for (rs <- runSources.filter(r => r.runId === runId && r.sourceId === sourceId)) yield rs.id).result
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)

    if (result.nonEmpty)
      result.head
    //here I have to create the runSource
    else {
      val idQuery: FixedSqlAction[Int, NoStream, Write] = (runSources returning runSources.map(_.id)) += (
        None, runId,sourceId,url,outputFolder,downloadEnabled,downloader,
        transformEnabled,transformer,loadEnabled,loader
        )
      val executionId = database.run(idQuery)
      val resultId = Await.result(executionId, Duration.Inf)
      resultId
    }
  }

  /**
    * Inserts the parameters used by a source
    * @param runSourceId source who is using the parameters
    * @param description explains what the parameter is used for
    * @param key indicates the name of the parameter
    * @param value indicates the value of the parameter
    * @return id of the parameter.
    */
  def runSourceParameterId(runSourceId: Int, description: String, key: String, value: String): Int = {
    //parameters have always to be created.
    val query = (runSourceParameters returning runSourceParameters.map(_.id)) += (
      None,runSourceId,description,key,value
      )
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)
    result
  }

  /**
    * generates the last representation of the dataset in the last run.
    * @param datasetId id for the dataset.
    * @param outputFolder working directory for the dataset.
    * @param downloadEnabled indicates if the dataset is being downloaded.
    * @param transformEnabled indicates if the dataset is being transformed.
    * @param loadEnabled indicates if the source is being loaded.
    * @param schemaUrl indicates the url of the schema.
    * @param schemaLocation indicates whether the schema is local or remote.
    * @return the runDataset id.
    */
  def runDatasetId(datasetId: Int, outputFolder: String, downloadEnabled: String, transformEnabled: String,
                   loadEnabled: String,schemaUrl: String, schemaLocation: String
                  ): Int = {
    val runId = getMaxRunNumber
    val query = (for (rd <- runDatasets.filter(r => r.runId === runId && r.datasetId === datasetId)) yield rd.id).result
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)

    if (result.nonEmpty)
      result.head
    //here I have to create the runSource
    else {
      val idQuery: FixedSqlAction[Int, NoStream, Write] = (runDatasets returning runDatasets.map(_.id)) += (
        None, runId,datasetId,outputFolder,downloadEnabled,transformEnabled,loadEnabled,schemaUrl,schemaLocation
        )
      val executionId = database.run(idQuery)
      val resultId = Await.result(executionId, Duration.Inf)
      resultId
    }
  }
  /**
    * generates the last representation of the dataset in the last run.
    * @param datasetId id for the dataset.
    * @param runId id for the run.
    * @return the runDataset id.
    */
  def runDatasetId(datasetId: Int, runId: Int
                  ): Int = {
    val query = (for (rd <- runDatasets.filter(r => r.runId === runId && r.datasetId === datasetId)) yield rd.id).result
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)
    if(result.nonEmpty)
      result.head
    else
      -1
  }

  /**
    * Inserts the parameters used by a source
    * @param runDatasetId dataset who is using the parameters
    * @param description explains what the parameter is used for
    * @param key indicates the name of the parameter
    * @param value indicates the value of the parameter
    * @return id of the parameter.
    */
  def runDatasetParameterId(runDatasetId: Int, description: String, key: String, value: String): Int = {
    //parameters have always to be created.
    val query = (runDatasetParameters returning runDatasetParameters.map(_.id)) += (
      None,runDatasetId,description,key,value
      )
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)
    result
  }
  /**
    * Inserts the parameters used by a source
    * @param runDatasetId dataset who is using the parameters
    * @param totalFiles explains what the parameter is used for
    * @param downloadedFiles indicates the name of the parameter
    * @return id of the parameter.
    */
  def runDatasetLogId(runDatasetId: Int, stage: STAGE.Value,totalFiles: Int, downloadedFiles: Int): Int = {
    //parameters have always to be created.
    val query = (runDatasetLogs returning runDatasetLogs.map(_.id)) += (
      None,runDatasetId,stage.toString,totalFiles,downloadedFiles
      )
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)
    result
  }
  /**
    * Inserts the parameters used by a source
    * @param totalFiles explains what the parameter is used for
    * @param downloadedFiles indicates the name of the parameter
    * @return id of the parameter.
    */
  def runDatasetLogAppend(datasetId: Int, stage: STAGE.Value,totalFiles: Int, downloadedFiles: Int): Int = {
    //parameters have always to be created.
    val runId = getMaxRunNumber
    val runDatasetIdAppend = runDatasetId(datasetId,runId)
    val query = (runDatasetLogs returning runDatasetLogs.map(_.id)) += (
      None,runDatasetIdAppend,stage.toString,totalFiles,downloadedFiles
      )
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)
    result
  }
  /**
    * Generates the versioning for the metadata of the files.
    * @param fileId indicats the file whose verions are.
    * @return id of the runFile.
    */
  def runFileId(fileId: Int): Int = {
    val runId = getMaxRunNumber
    val query = (for (rf <- runFiles.filter(r => r.runId === runId && r.fileId === fileId)) yield rf.id).result
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)

    //I get the data from the FILES table
    val fileFieldsQuery = (for (f <- files.filter(_.id === fileId)) yield (
      f.status, f.size, f.lastUpdate, f.hash, f.originSize, f.originLastUpdate, f.dateProcessed)).result
    val fileFields = Await.result(database.run(fileFieldsQuery), Duration.Inf).head

    //here I have to write the actual status of the file to the runfile.
    if (result.nonEmpty) {
      val updateQuery = (for (f <- runFiles.filter(r => r.runId === runId && r.fileId === fileId))
        yield (f.status, f.size, f.lastUpdate, f.hash, f.originSize, f.originLastUpdate, f.dateProcessed))
        .update(fileFields._1, fileFields._2, fileFields._3, fileFields._4, fileFields._5, fileFields._6, fileFields._7)
      Await.result(database.run(updateQuery),Duration.Inf)
      result.head
    }
    //here I have to create the runFile
    else {
      //and then I create the version of the runfiles.
      val idQuery: FixedSqlAction[Int, NoStream, Write] = (runFiles returning runFiles.map(_.id)) += (
        None, runId, fileId, fileFields._1, fileFields._2, fileFields._3,
        fileFields._4, fileFields._5, fileFields._6, fileFields._7
        )
      val executionId = database.run(idQuery)
      val resultId = Await.result(executionId, Duration.Inf)
      resultId
    }
  }
  //-------------------------------Run closing--------------------------------------------------------------------------
  /**
    * puts the time finished of the run
    * @param runId id for the run.
    */
  def endRun(runId: Int): Unit ={
    val dateTimeEnd = DateTime.now().toString
    val updateQuery = (for (r <- runs.filter(f => f.id === runId)) yield r.datetimeEnd).update(dateTimeEnd)
    val execution = database.run(updateQuery)
    /*val result = */
    Await.result(execution, Duration.Inf)
  }
  //------------------------------FILE OPERATIONS SECTION FILENAME/CHECKIFUPDATE/PROCESS--------------------------------
  /**
    * By receiving a candidate name returns a unique name inside the dataset.
    * @param fileId id for the file.
    * @return unique name among the dataset's files. 0 as the Int indicates the file should not exist.
    */
  def getFileNameAndCopyNumber(fileId: Int): (String,Int) = {
    val query = (for (f <- files.filter(f => f.id === fileId)) yield (f.name, f.datasetId, f.copyNumber, f.stage)).result
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)

    if (result.nonEmpty) {
      if (result.head._3 != 0) //this indicates the copynumber has been assigned
        (result.head._1, result.head._3)
      //while copynumber is 0 means the value has not been assigned.
      else
        getFileName(fileId, result.head._1, result.head._2, 1, STAGE.withName(result.head._4))
    }
    else
      ("FileDoesNotExist", 0)
  }
  /**
    * returns hash, size and last update.
    * @param fileId identifier of the file.
    * @return hash, size and last update.
    */
  def getFileDetails(fileId: Int): (String,String,String) ={
    val query = (for (f <- files.filter(f => f.id === fileId)) yield (f.hash, f.size, f.lastUpdate)).result
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)

    if (result.nonEmpty)
      result.head
    else
      ("file","does not","exist")
  }
  /**
    * By receiving a candidate name returns a unique name inside the dataset.
    * @param fileId id for the file.
    * @param name candidate name.
    * @param datasetId dataset.
    * @param copyNumber actual guess of the number of copy the file is.
    * @return unique name among the dataset's files.
    */
  private def getFileName(fileId: Int, name: String, datasetId: Int, copyNumber: Int, stage: STAGE.Value): (String,Int) ={
    val query = (for (s <- files.filter(f => f.datasetId === datasetId && f.stage === stage.toString &&
      f.name === name && f.copyNumber === copyNumber && f.id =!= fileId)) yield s.id).result
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)

    //this means the name is already in use. I have to recursively get a new name.
    if (result.nonEmpty)
      getFileName(fileId, name, datasetId, copyNumber+1, stage)
    //here I have to create the file.
    else {
      val updateQuery = (
        for (s <- files.filter(f => f.id === fileId)) yield (s.name,s.copyNumber)).update(name,copyNumber)
      val executionId = database.run(updateQuery)
      /*val result = */
      Await.result(executionId, Duration.Inf)
      (name,copyNumber)
    }
  }

  /**
    * indicates which is the maximum copy number for the same filename inside the same dataset.
    * @param datasetId datast where the file belongs
    * @param fileName original file name
    * @param stage indicates whether download/transform
    * @return max copy number
    */
  def getMaxCopyNumber(datasetId: Int, fileName: String, stage: STAGE.Value): Int ={
    val query = (for (s <- files.filter(f => f.datasetId === datasetId &&
      f.name === fileName && f.stage === stage.toString)
    ) yield s.copyNumber).result
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)
    result.max
  }

  /**
    * gets the actual run
    * @return max id of runs
    */
  def getMaxRunNumber: Int ={
    val query = (for (r <- runs) yield r.id).result
    val execution = database.run(query)
    val result = Await.result(execution, Duration.Inf)
    result.max
  }

  /**
    * checks if the given file has to be updated based on its hash, size and last update.
    * @param fileId id for the file.
    * @param hash hash of the file.
    * @param originSize original size in the source.
    * @param originLastUpdate original last updated in the source.
    * @return true = has to be updated.
    */
  def checkIfUpdateFile(fileId: Int, hash: String, originSize: String, originLastUpdate: String): Boolean ={

    val query = for (f <- files.filter(f => f.id === fileId)) yield (f.status, f.hash, f.originSize, f.originLastUpdate)

    val queryResult = query.result
    val execution = database.run(queryResult)
    val result = Await.result(execution, Duration.Inf)

    if(result.nonEmpty){
      val oldStatus = result.head._1
      val oldHash = result.head._2
      val oldOriginSize = result.head._3
      val oldOriginLastUpdate = result.head._4

      //UPDATE indicates that file was put on the download folder and marked as update
      if(oldStatus.equalsIgnoreCase(FILE_STATUS.UPDATED.toString))
        false
      //FAILED indicates that the file was not put in the folder, OUTDATED means the file was deleted from the server
      else if (oldStatus.equalsIgnoreCase(FILE_STATUS.FAILED.toString) ||
        oldStatus.equalsIgnoreCase(FILE_STATUS.OUTDATED.toString) ||
        oldOriginSize != originSize || oldOriginLastUpdate != originLastUpdate ||
        (oldHash != hash && hash != "")
      ) {
        Await.result(database
          .run((for (f <- files.filter(f => f.id === fileId)) yield (f.hash,f.originSize,f.originLastUpdate))
            .update(hash,originSize,originLastUpdate))
          , Duration.Inf
        )
        true
      }
      //any other case whilst COMPARE, shouldn't be downloaded
      else if(oldStatus.equalsIgnoreCase(FILE_STATUS.COMPARE.toString)) {
        Await.result(database
          .run((for (f <- files.filter(f => f.id === fileId)) yield f.status)
            .update(FILE_STATUS.UPDATED.toString))
          , Duration.Inf
        )
        false
      }
      else false
    }
    else false
  }

  /**
    * returns all the non outdated files with its copy number.
    * @param datasetId dataset from where files are required.
    * @return (fileId, filename, copyNumber)
    */
  def getFilesToProcess(datasetId: Int, stage: STAGE.Value):Seq[(Int,String,Int)]={
    val query = (for (f <- files.filter(f => f.datasetId === datasetId && f.stage === stage.toString &&
      (f.status === FILE_STATUS.UPDATED.toString))
    ) yield (f.id,f.name,f.copyNumber)).result
    val execution = database.run(query)
    Await.result(execution, Duration.Inf)
  }
  /**
    * marks indicated file as to be UPDATED.
    * @param fileId identifier for the file.
    */
  def markAsUpdated(fileId: Int, size:String): Unit ={
    val query = (for (f <- files.filter(f => f.id === fileId ))
      yield (f.status,f.size,f.lastUpdate)).update(FILE_STATUS.UPDATED.toString,size,DateTime.now().toString)
    val execution = database.run(query)
    Await.result(execution, Duration.Inf)
    runFileId(fileId)
  }
  /**
    * marks indicated file as to be UPDATED.
    * @param fileId identifier for the file.
    */
  def markAsUpdated(fileId: Int, size:String, hash: String): Unit ={
    val query = (for (f <- files.filter(f => f.id === fileId ))
      yield (f.status,f.size,f.lastUpdate,f.hash)).update(FILE_STATUS.UPDATED.toString,size,DateTime.now().toString,hash)
    val execution = database.run(query)
    Await.result(execution, Duration.Inf)
    runFileId(fileId)
  }
  /**
    * to be used when the file download or transformation fails, puts file status into FAILED
    * @param fileId identifier for the file.
    */
  def markAsFailed(fileId: Int): Unit ={
    val query = (for (f <- files.filter(f => f.id === fileId ))
      yield (f.status,f.lastUpdate)).update(FILE_STATUS.FAILED.toString,DateTime.now().toString)
    val execution = database.run(query)
    Await.result(execution, Duration.Inf)
    runFileId(fileId)
  }
  /**
    * mark all files that have not been compared into the log as outdated.
    * meant to be used at the end of all comparisons (all check if udpate)
    * changes COMPARE to OUTDATED.
    * @param datasetId identifier for the dataset.
    * @param stage indicates whether refers to download or transformed files.
    */
  def markAsOutdated(datasetId: Int, stage: STAGE.Value): Unit ={
    val queryIds = Await.result(database.run((for(f<- files.filter(f => f.datasetId === datasetId &&
      f.status === FILE_STATUS.COMPARE.toString && f.stage === stage.toString))yield f.id).result),Duration.Inf)

    val query = (
      for (f <- files.filter(
        f => f.datasetId === datasetId && f.status === FILE_STATUS.COMPARE.toString && f.stage === stage.toString
      ))yield f.status).update(FILE_STATUS.OUTDATED.toString)

    val execution = database.run(query)
    Await.result(execution, Duration.Inf)

    queryIds.map(runFileId)
  }
  /**
    * mark all the files with any status into status COMPARE
    * meant to be used to check which files have been deleted from the source.
    * @param datasetId identifier for the dataset.
    * @param stage indicates whether refers to download or transformed files.
    */
  def markToCompare(datasetId: Int, stage: STAGE.Value): Unit ={
    val query = (for (f <- files.filter(f => f.datasetId === datasetId
      && f.stage === stage.toString)
    )yield f.status).update(FILE_STATUS.COMPARE.toString)
    val execution = database.run(query)
    Await.result(execution, Duration.Inf)
  }
/*  /**
    * updates the status of the files in the log in order to inform that was already processed.
    * turns "UPDATE"
    * updates dateProcessed
    * @param datasetId identifier for the dataset.
    * @param stage indicates whether refers to download or transformed files.
    */
  def markAsProcessed(datasetId: Int, stage: STAGE.Value): Unit ={
    val queryIds = Await.result(database.run((for (f <- files.filter(f => f.datasetId === datasetId &&
      f.status === FILE_STATUS.UPDATE.toString && f.stage === stage.toString))yield f.id).result),Duration.Inf)

    val query = (for (f <- files.filter(f => f.datasetId === datasetId &&
      f.status === FILE_STATUS.UPDATE.toString && f.stage === stage.toString)
    )yield (f.status,f.dateProcessed)).update(FILE_STATUS.UPDATED.toString,DateTime.now().toString)
    val execution = database.run(query)
    Await.result(execution, Duration.Inf)

    queryIds.map(runFileId)
  }*/

  def insertMessage(runId: Int, message: String): Unit ={
    val query= runMessages += (runId, message)
    val execution = database.run(query)
    val resultId = Await.result(execution, Duration.Inf)
  }

  //------------------------------DATABASE BASIC OPERATIONS OPEN/CLOSE--------------------------------------------------
  /**
    * Opens or create the database, checks the existence of its tables and creates them if do not exist.
    * @param path directory where the database file is.
    */
  def setDatabase(path: String): Unit = {
    //;DB_CLOSE_ON_EXIT=FALSE
    //jdbc:h2:file:/home/nachon/Downloads/tesis/db/db
    database = Database.forURL("jdbc:h2:file:" + path + "/db;AUTO_SERVER=TRUE", driver = "org.h2.Driver", keepAliveConnection = true)
    val tables = Await.result(database.run(MTable.getTables), Duration.Inf).toList
    if (!tables.exists(_.name.name == "SOURCES")) {
      val setup = DBIO.seq(sources.schema.create)
      val setupFuture = database.run(setup)
      Await.result(setupFuture,Duration.Inf)
      logger.info("Table SOURCES created")
    }
    if (!tables.exists(_.name.name == "DATASETS")) {
      val setup = DBIO.seq(datasets.schema.create)
      val setupFuture = database.run(setup)
      Await.result(setupFuture,Duration.Inf)
      logger.info("Table DATASETS created")
    }
    if (!tables.exists(_.name.name == "FILES")) {
      val setup = DBIO.seq(files.schema.create)
      val setupFuture = database.run(setup)
      Await.result(setupFuture,Duration.Inf)
      logger.info("Table FILES created")
    }
    if (!tables.exists(_.name.name == "RUNS")) {
      val setup = DBIO.seq(runs.schema.create)
      val setupFuture = database.run(setup)
      Await.result(setupFuture,Duration.Inf)
      logger.info("Table RUNS created")
    }
    if (!tables.exists(_.name.name == "RUNSOURCES")) {
      val setup = DBIO.seq(runSources.schema.create)
      val setupFuture = database.run(setup)
      Await.result(setupFuture,Duration.Inf)
      logger.info("Table RUNSOURCES created")
    }
    if (!tables.exists(_.name.name == "RUNSOURCEPARAMETERS")) {
      val setup = DBIO.seq(runSourceParameters.schema.create)
      val setupFuture = database.run(setup)
      Await.result(setupFuture,Duration.Inf)
      logger.info("Table RUNSOURCEPARAMETERS created")
    }
    if (!tables.exists(_.name.name == "RUNDATASETS")) {
      val setup = DBIO.seq(runDatasets.schema.create)
      val setupFuture = database.run(setup)
      Await.result(setupFuture,Duration.Inf)
      logger.info("Table RUNDATASETS created")
    }
    if (!tables.exists(_.name.name == "RUNDATASETPARAMETERS")) {
      val setup = DBIO.seq(runDatasetParameters.schema.create)
      val setupFuture = database.run(setup)
      Await.result(setupFuture,Duration.Inf)
      logger.info("Table RUNDATASETPARAMETERS created")
    }
    if (!tables.exists(_.name.name == "RUNDATASETLOGS")) {
      val setup = DBIO.seq(runDatasetLogs.schema.create)
      val setupFuture = database.run(setup)
      Await.result(setupFuture,Duration.Inf)
      logger.info("Table RUNDATASETLOGS created")
    }

    if (!tables.exists(_.name.name == "RUNFILES")) {
      val setup = DBIO.seq(runFiles.schema.create)
      val setupFuture = database.run(setup)
      Await.result(setupFuture,Duration.Inf)
      logger.info("Table RUNFILES created")
    }
  }

  /**
    * closes the database connection.
    */
  def closeDatabase(): Unit = {
    val closing = database.shutdown
    Await.result(closing,Duration.Inf)
  }
  //-------------------------------------DATABASE SCHEMAS---------------------------------------------------------------

  //---------------------------------- Definition of the SOURCES table--------------------------------------------------
  /**
    * SOURCES TABLE:
    *   ID:   INT     PK AUTOINC
    *   NAME: STRING
    * @param tag SOURCES
    */
  class Sources(tag: Tag) extends
    Table[(Option[Int], String)](tag, "SOURCES") {
    def id = column[Int]("SOURCE_ID", O.PrimaryKey, O.AutoInc)

    def name = column[String]("NAME")

    def * = (id.?, name)
  }

  val sources = TableQuery[Sources]
  //------------------------------------- Definition of the DATASETS table----------------------------------------------
  /**
    * DATASETS TABLE:
    *   ID:         INT     PK AUTOINC
    *   SOURCE_ID:  INT     FK(SOURCES)
    *   NAME:       STRING
    * @param tag DATASETS
    */
  class Datasets(tag: Tag) extends
    Table[(Option[Int], Int, String)](tag, "DATASETS") {
    def id = column[Int]("DATASET_ID", O.PrimaryKey, O.AutoInc)

    def sourceId = column[Int]("SOURCE_ID")

    def name = column[String]("NAME")

    def Source = foreignKey("DATASETS_SOURCE_FK", sourceId, sources)(
      _.id,
      onUpdate = ForeignKeyAction.Restrict,
      onDelete = ForeignKeyAction.Cascade
    )

    def * = (id.?, sourceId, name)
  }

  val datasets = TableQuery[Datasets]

  //----------------------------------------- Definition of the FILES table---------------------------------------------
  /**
    * FILES TABLE:
    *   ID:                     INT     PK AUTOINC
    *   DATASET_ID:             INT     FK(DATASET)
    *   URL:                    STRING
    *   NAME:                   STRING
    *   STAGE:                  STRING
    *   STATUS:                 STRING
    *   SIZE:                   STRING
    *   LAST_UPDATE:            STRING
    *   HASH:                   STRING
    *   SIZE_IN_ORIGIN:         STRING
    *   LAST_UPDATE_IN_ORIGIN:  STRING
    *   DATE_PROCESSED:         STRING
    *   COPY_NUMBER:            INT
    * @param tag FILES
    */
  class Files(tag: Tag) extends
    Table[(Option[Int], Int, String, String, String, String, String,
      String, String, String, String, String, Int)](tag, "FILES") {
    def id = column[Int]("FILE_ID", O.PrimaryKey, O.AutoInc)

    def datasetId = column[Int]("DATASET_ID")

    def url = column[String]("URL")

    def name = column[String]("NAME")

    def stage = column[String]("STAGE")

    //THIS IS DOWNLOAD/TRANSFORM
    def status = column[String]("STATUS")

    //UPDATED/FAILED/OUTDATED
    def size = column[String]("SIZE")

    def lastUpdate = column[String]("LAST_UPDATE")

    def hash = column[String]("HASH")

    def originSize = column[String]("SIZE_IN_ORIGIN")

    def originLastUpdate = column[String]("LAST_UPDATE_IN_ORIGIN")

    def dateProcessed = column[String]("DATE_PROCESSED")

    def copyNumber = column[Int]("COPY_NUMBER")

    def Dataset = foreignKey("FILES_DATASET_FK", datasetId, datasets)(
      _.id,
      onUpdate = ForeignKeyAction.Restrict,
      onDelete = ForeignKeyAction.Cascade
    )

    def * = (id.?, datasetId, url, name, stage, status, size, lastUpdate, hash,
      originSize, originLastUpdate, dateProcessed, copyNumber)
  }

  val files = TableQuery[Files]

  //------------------------------------- Definition of the RUNS table--------------------------------------------------
  /**
    * RUNS TABLE:
    *   ID:                 INT     PK AUTOINC
    *   DATETIME_START:     STRING
    *   DATETIME_END:       STRING
    *   DOWNLOAD_ENABLED:   STRING
    *   TRANSFORM_ENABLED:  STRING
    *   LOAD_ENABLED:       STRING
    *   OUTPUT_FOLDER:      STRING
    * @param tag RUNS
    */
  class Runs(tag: Tag) extends
    Table[(Option[Int], String,String, String, String, String, String)](tag, "RUNS") {
    def id = column[Int]("RUN_ID", O.PrimaryKey, O.AutoInc)

    def datetimeStart = column[String]("DATETIME_START")

    def datetimeEnd = column[String]("DATETIME_END")

    def downloadEnabled = column[String]("DOWNLOAD_ENABLED")

    def transformEnabled = column[String]("TRANSFORM_ENABLED")

    def loadEnabled = column[String]("LOAD_ENABLED")

    def outputFolder = column[String]("OUTPUT_FOLDER")

    def * = (id.?, datetimeStart,datetimeEnd, downloadEnabled, transformEnabled, loadEnabled, outputFolder)
  }

  val runs = TableQuery[Runs]

  //------------------------------------------- Definition of the RUNSOURCES table--------------------------------------
  /**
    * RUNSOURCES TABLE:
    *   ID:                 INT     PK AUTOINC
    *   RUN_ID:             INT     FK(RUNS)
    *   SOURCE_ID:          INT     FK(SOURCES)
    *   URL:                STRING
    *   OUTPUT_FOLDER:      STRING
    *   DOWNLOAD_ENABLED:   STRING
    *   DOWNLOADER:         STRING
    *   TRANSFORM_ENABLED:  STRING
    *   TRANSFORMER:        STRING
    *   LOAD_ENABLED:       STRING
    *   LOADER:             STRING
    * @param tag RUNSOURCES
    */
  class RunSources(tag: Tag) extends
    Table[(Option[Int], Int, Int, String, String, String, String, String, String, String, String)](tag, "RUNSOURCES") {
    def id = column[Int]("RUNSOURCE_ID", O.PrimaryKey, O.AutoInc)

    def runId = column[Int]("RUN_ID")

    def sourceId = column[Int]("SOURCE_ID")

    def url = column[String]("URL")

    def outputFolder = column[String]("OUTPUT_FOLDER")

    def downloadEnabled = column[String]("DOWNLOAD_ENABLED")

    def downloader = column[String]("DOWNLOADER")

    def transformEnabled = column[String]("TRANSFORM_ENABLED")

    def transformer = column[String]("TRANSFORMER")

    def loadEnabled = column[String]("LOAD_ENABLED")

    def loader = column[String]("LOADER")

    def Source = foreignKey("RUNSOURCES_SOURCE_FK", sourceId, sources)(
      _.id,
      onUpdate = ForeignKeyAction.Restrict,
      onDelete = ForeignKeyAction.Cascade
    )

    def Run = foreignKey("RUNSOURCES_Run_FK", runId, runs)(
      _.id,
      onUpdate = ForeignKeyAction.Restrict,
      onDelete = ForeignKeyAction.Cascade
    )

    def * = (id.?, runId, sourceId, url, outputFolder, downloadEnabled,
      downloader, transformEnabled, transformer, loadEnabled, loader)
  }

  val runSources = TableQuery[RunSources]

  //------------------------------------ Definition of the RUNSOURCEPARAMETERS table------------------------------------
  /**
    * RUNSOURCEPARAMETERS TABLE:
    *   ID:           INT     PK AUTOINC
    *   RUNSOURCE_ID: INT     FK(RUNSOURCES)
    *   DESCRIPTION:  STRING
    *   KEY:          STRING
    *   VALUE:        STRING
    * @param tag RUNSOURCEPARAMETERS
    */
  class RunSourceParameters(tag: Tag) extends
    Table[(Option[Int], Int, String, String, String)](tag, "RUNSOURCEPARAMETERS") {
    def id = column[Int]("RUNSOURCEPARAMETER_ID", O.PrimaryKey, O.AutoInc)

    def runSourceId = column[Int]("RUNSOURCE_ID")

    def description = column[String]("DESCRIPTION")

    def key = column[String]("KEY")

    def value = column[String]("VALUE")

    def RunSource = foreignKey("RUNSOURCEPARAMETERS_RUNSOURCE_FK", runSourceId, runSources)(
      _.id,
      onUpdate = ForeignKeyAction.Restrict,
      onDelete = ForeignKeyAction.Cascade
    )

    def * = (id.?, runSourceId, description, key, value)
  }

  val runSourceParameters = TableQuery[RunSourceParameters]

  //------------------------------------------- Definition of the RUNDATASETS table-------------------------------------
  /**
    * RUNDATASETS TABLE:
    *   ID:                 INT     PK AUTOINC
    *   RUN_ID:             INT     FK(RUNS)
    *   DATASET_ID:         INT     FK(DATASETS)
    *   OUTPUT_FOLDER:      STRING
    *   DOWNLOAD_ENABLED:   STRING
    *   TRANSFORM_ENABLED:  STRING
    *   LOAD_ENABLED:       STRING
    *   SCHEMA_LOCATION:    STRING
    *   SCHEMA_URL:         STRING
    * @param tag RUNDATASETS
    */
  class RunDatasets(tag: Tag) extends
    Table[(Option[Int], Int, Int, String, String, String, String, String, String)](tag, "RUNDATASETS") {
    def id = column[Int]("RUNDATASET_ID", O.PrimaryKey, O.AutoInc)

    def runId = column[Int]("RUN_ID")

    def datasetId = column[Int]("DATASET_ID")

    def outputFolder = column[String]("OUTPUT_FOLDER")

    def downloadEnabled = column[String]("DOWNLOAD_ENABLED")

    def transformEnabled = column[String]("TRANSFORM_ENABLED")

    def loadEnabled = column[String]("LOAD_ENABLED")

    def schemaLocation = column[String]("SCHEMA_LOCATION")

    def schemaUrl = column[String]("SCHEMA_URL")

    def Dataset = foreignKey("RUNDATASETS_DATASET_FK", datasetId, datasets)(
      _.id,
      onUpdate = ForeignKeyAction.Restrict,
      onDelete = ForeignKeyAction.Cascade
    )

    def Run = foreignKey("RUNDATASETS_Run_FK", runId, runs)(
      _.id,
      onUpdate = ForeignKeyAction.Restrict,
      onDelete = ForeignKeyAction.Cascade
    )

    def * = (id.?,runId,datasetId,outputFolder,downloadEnabled,transformEnabled,loadEnabled,schemaLocation,schemaUrl)
  }

  val runDatasets = TableQuery[RunDatasets]

  //--------------------------------------- Definition of the RUNDATASETPARAMETERS table---------------------------------
  /**
    * RUNDATASETPARAMETERS TABLE:
    *   ID:             INT     PK AUTOINC
    *   RUNDATASET_ID:  INT     FK(RUNDATASETS)
    *   DESCRIPTION:    STRING
    *   KEY:            STRING
    *   VALUE:          STRING
    * @param tag RUNDATASETPARAMETERS
    */
  class RunDatasetParameters(tag: Tag) extends
    Table[(Option[Int], Int, String, String, String)](tag, "RUNDATASETPARAMETERS") {
    def id = column[Int]("RUNDATASETPARAMETER_ID", O.PrimaryKey, O.AutoInc)

    def runDatasetId = column[Int]("RUNDATASET_ID")

    def description = column[String]("DESCRIPTION")

    def key = column[String]("KEY")

    def value = column[String]("VALUE")

    def RunDataset = foreignKey("RUNDATASETPARAMETERS_RUNDATASET_FK", runDatasetId, runDatasets)(
      _.id,
      onUpdate = ForeignKeyAction.Restrict,
      onDelete = ForeignKeyAction.Cascade
    )

    def * = (id.?,runDatasetId,description,key,value)
  }

  val runDatasetParameters = TableQuery[RunDatasetParameters]

  //--------------------------------------- Definition of the RUNDATASETLOGS table---------------------------------
  /**
    * RUNDATASETLOGS TABLE:
    *   ID:              INT     PK AUTOINC
    *   RUNDATASET_ID:   INT     FK(RUNDATASETS)
    *   STAGE:           STRING
    *   TOTAL_FILES:     INT
    *   DOWNLOADED_FILES:INT
    * @param tag RUNDATASETLOGS
    */
  class RunDatasetLogs(tag: Tag) extends
    Table[(Option[Int], Int, String, Int, Int)](tag, "RUNDATASETLOGS") {
    def id = column[Int]("RUNDATASETLOGS_ID", O.PrimaryKey, O.AutoInc)

    def runDatasetId = column[Int]("RUNDATASET_ID")

    def stage = column[String]("STAGE")

    def totalFiles = column[Int]("TOTAL_FILES")

    def downloadedFiles = column[Int]("DOWNLOADED_FILES")

    def RunDataset = foreignKey("RUNDATASETLOGS_RUNDATASET_FK", runDatasetId, runDatasets)(
      _.id,
      onUpdate = ForeignKeyAction.Restrict,
      onDelete = ForeignKeyAction.Cascade
    )

    def * = (id.?,runDatasetId,stage,totalFiles,downloadedFiles)
  }

  val runDatasetLogs = TableQuery[RunDatasetLogs]

  //--------------------------------------------- Definition of the RUNFILES table--------------------------------------
  /**
    * RUNFILES TABLE:
    *   ID:                     INT     PK AUTOINC
    *   RUN_ID:                 INT     FK(RUNS)
    *   FILES:                  INT     FK(FILES)
    *   STATUS:                 STRING
    *   SIZE:                   STRING
    *   LAST_UPDATE:            STRING
    *   HASH:                   STRING
    *   SIZE_IN_ORIGIN:         STRING
    *   LAST_UPDATE_IN_ORIGIN:  STRING
    *   DATE_PROCESSED:         STRING
    * @param tag RUNFILES
    */
  class RunFiles(tag: Tag) extends
    Table[(Option[Int], Int, Int, String, String, String, String, String, String, String)](tag, "RUNFILES") {
    def id = column[Int]("RUNFILE_ID", O.PrimaryKey, O.AutoInc)

    def runId = column[Int]("RUN_ID")

    def fileId = column[Int]("FILE_ID")

    //THIS IS DOWNLOAD/TRANSFORM
    def status = column[String]("STATUS")

    //UPDATED/FAILED/OUTDATED
    def size = column[String]("SIZE")

    def lastUpdate = column[String]("LAST_UPDATE")

    def hash = column[String]("HASH")

    def originSize = column[String]("SIZE_IN_ORIGIN")

    def originLastUpdate = column[String]("LAST_UPDATE_IN_ORIGIN")

    def dateProcessed = column[String]("DATE_PROCESSED")

    def File = foreignKey("RUNFILES_FILE_FK", fileId, files)(
      _.id,
      onUpdate = ForeignKeyAction.Restrict,
      onDelete = ForeignKeyAction.Cascade
    )
//    def pk = primaryKey("pk_a", (k1, k2))

    def * = (id.?,runId, fileId, status, size, lastUpdate, hash, originSize, originLastUpdate, dateProcessed)
  }

  val runFiles = TableQuery[RunFiles]

  //------------------------------------- Definition of the RUNMESSAGES table----------------------------------------------
  /**
    * RUNMESSAGES TABLE:
    *   RUN_ID:     INT     FK(SOURCES)
    *   TEXT:       STRING
    * @param tag DATASETS
    */
  class RunMessages(tag: Tag) extends
    Table[(Int, String)](tag, "RUNMESSAGES") {

    def runId = column[Int]("SOURCE_ID")

    def text = column[String]("TEXT")

    def Source = foreignKey("RUNMESSAGES_RUN_FK", runId, runs)(
      _.id,
      onUpdate = ForeignKeyAction.Restrict,
      onDelete = ForeignKeyAction.Cascade
    )

    def * = (runId, text)
  }

  val runMessages = TableQuery[RunMessages]
}